{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eQ9bDYzsw1rS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Link : https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "id": "u1awzceIw20e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('names.txt') as f:\n",
        "    names = f.read().splitlines()"
      ],
      "metadata": {
        "id": "jnqWqH5Iw-VQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hzw8ge2-w-1T",
        "outputId": "95867efa-e2d0-4f6f-e12c-a596ebd10b25"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = ['.'] + list(string.ascii_lowercase)\n",
        "t_i = {t:i for i,t in enumerate(tokens)}\n",
        "i_t = {i:t for t,i in t_i.items()}"
      ],
      "metadata": {
        "id": "DcC1cqgmxAkx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating training set\n",
        "\n",
        "inputs = []\n",
        "targets = []"
      ],
      "metadata": {
        "id": "emnSHm_2xJhE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in names[:1]:\n",
        "    word = ['.'] + list(word) + ['.']\n",
        "    for ch1, ch2 in zip(word,word[1:]):\n",
        "        r = t_i[ch1]\n",
        "        c = t_i[ch2]\n",
        "        inputs.append(r)\n",
        "        targets.append(c)"
      ],
      "metadata": {
        "id": "BElwcRtQxMWm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor(inputs)\n",
        "targets = torch.tensor(targets)\n",
        "inputs, targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn7ScB5hxSss",
        "outputId": "00fe7a64-e01e-4efa-bb8b-2ca69d84df51"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0,  5, 13, 13,  1]), tensor([ 5, 13, 13,  1,  0]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we one-hot encode these int tensors\n",
        "\n",
        "X_enc = F.one_hot(inputs, num_classes=len(tokens))"
      ],
      "metadata": {
        "id": "nSLYhsbuyZj1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_enc.shape)\n",
        "plt.imshow(X_enc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "71Qs0UgmybzH",
        "outputId": "16be7bfe-9786-48c9-9018-e797230b208c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 27])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x79a568d410c0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_enc.dtype # we need float for inputs not int64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YqlJ9vbygcr",
        "outputId": "46c9bf69-84e6-46d0-be7b-a8e19bc08ffd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to convert them into float32\n",
        "X_enc.float()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfdMOeSlyjO-",
        "outputId": "13472457-8014-43da-ecb2-4a36672902c7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.randn(size=(len(tokens),1))\n",
        "\"\"\"\n",
        "w: 27x1\n",
        "X: 5x27\n",
        "\n",
        "X@w: 5x1\n",
        "\"\"\"\n",
        "X_enc.float() @ w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHR1CW-jyqFB",
        "outputId": "f7e0169d-5e5f-43c8-b111-a533883fd3c8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5952],\n",
              "        [ 0.6204],\n",
              "        [ 1.6618],\n",
              "        [ 1.6618],\n",
              "        [-0.1022]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's use 27 neurons, because for each given input example, we will have 27 values, each showing the likelihood of the next character. The correct target should have the highest value and we will train it in this manner\n",
        "# weights of each neuron are along the column\n",
        "\"\"\"\n",
        "w: 27x27\n",
        "X: 5x27\n",
        "\n",
        "X@w: 5x27\n",
        "\"\"\"\n",
        "\n",
        "w = torch.randn(size=(27,27))\n",
        "(X_enc.float() @ w).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiWqf4rgyxe6",
        "outputId": "253d7064-bf69-4ec4-ede3-1b057eb36d91"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since the numbers are some random positive and negative values. We interpret them as log counts.\n",
        "# And since we want to generate the table that we build in bigram, but this time using NN,\n",
        "# We will exponentiate them, so all will become positive numbers, and then we can get the probabilities\n",
        "\n",
        "logits = (X_enc.float() @ w)\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1 , keepdims = True)\n",
        "# The last two lines are called softmax.\n",
        "probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okzKtAO7y03e",
        "outputId": "a018ce28-0a26-4e7d-d1fd-097a7907e21d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0065, 0.0147, 0.0149, 0.0386, 0.0260, 0.0150, 0.0350, 0.0055, 0.0058,\n",
              "         0.0025, 0.0126, 0.0357, 0.0319, 0.0332, 0.0282, 0.1587, 0.0153, 0.0068,\n",
              "         0.0883, 0.0403, 0.2433, 0.0094, 0.0398, 0.0200, 0.0242, 0.0182, 0.0297],\n",
              "        [0.0108, 0.0373, 0.0436, 0.0105, 0.0102, 0.0165, 0.0241, 0.0103, 0.1565,\n",
              "         0.0411, 0.0274, 0.0314, 0.0054, 0.0460, 0.0130, 0.0259, 0.0368, 0.0071,\n",
              "         0.0661, 0.0635, 0.0202, 0.0267, 0.0287, 0.0333, 0.1392, 0.0316, 0.0365],\n",
              "        [0.0106, 0.0257, 0.0100, 0.0362, 0.0035, 0.0116, 0.0426, 0.1217, 0.0122,\n",
              "         0.0041, 0.0221, 0.0513, 0.1904, 0.0458, 0.0067, 0.0326, 0.0191, 0.0270,\n",
              "         0.1061, 0.0093, 0.0112, 0.0307, 0.0313, 0.0737, 0.0388, 0.0023, 0.0232],\n",
              "        [0.0106, 0.0257, 0.0100, 0.0362, 0.0035, 0.0116, 0.0426, 0.1217, 0.0122,\n",
              "         0.0041, 0.0221, 0.0513, 0.1904, 0.0458, 0.0067, 0.0326, 0.0191, 0.0270,\n",
              "         0.1061, 0.0093, 0.0112, 0.0307, 0.0313, 0.0737, 0.0388, 0.0023, 0.0232],\n",
              "        [0.0654, 0.0347, 0.0089, 0.0934, 0.0672, 0.0109, 0.0355, 0.0105, 0.0110,\n",
              "         0.0121, 0.1224, 0.0514, 0.1211, 0.0025, 0.0340, 0.0173, 0.0170, 0.0432,\n",
              "         0.0262, 0.0153, 0.0034, 0.0448, 0.0240, 0.0157, 0.0156, 0.0446, 0.0518]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs.sum(dim = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzSsyQQ10wZa",
        "outputId": "1559f724-dded-46ee-c675-7724a6b2bb11"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets[0] , probs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0q-YD9fZ0z9x",
        "outputId": "d6e9ac6a-ada7-4a51-e95b-155f1eaf7b11"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(5),\n",
              " tensor([0.0065, 0.0147, 0.0149, 0.0386, 0.0260, 0.0150, 0.0350, 0.0055, 0.0058,\n",
              "         0.0025, 0.0126, 0.0357, 0.0319, 0.0332, 0.0282, 0.1587, 0.0153, 0.0068,\n",
              "         0.0883, 0.0403, 0.2433, 0.0094, 0.0398, 0.0200, 0.0242, 0.0182, 0.0297]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can see that, we have a target value, and the predicted probability by NN. So now we need to calculate the weights and then backpropogate to minimize the loss"
      ],
      "metadata": {
        "id": "Og9ytWs41AD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlls = torch.zeros(5)\n",
        "\n",
        "for i in range(5):\n",
        "  # For the i-th bigram\n",
        "  x = inputs[i].item()\n",
        "  y = targets[i].item()\n",
        "  print('-'*25)\n",
        "  print(f\"bigram: {i_t[x]}{i_t[y]}\\tindices: {x},{y}\")\n",
        "  print(f\"neural network input: {x}\")\n",
        "  print(f\"output probabilities: {probs[i]}\")\n",
        "  print(f\"actual output [label]: {y}\")\n",
        "  p = probs[i,y]\n",
        "  print(f\"predicted label probability: {p.item()}\")\n",
        "\n",
        "  logp = torch.log(p)\n",
        "  nll = -logp\n",
        "  print(f\"log likelihood: {logp}\\tnegative log likelihood: {nll}\")\n",
        "  nlls[i] = nll\n",
        "  print('-'*25)\n",
        "\n",
        "print('==='*10)\n",
        "print(f\"average nll: {nlls.mean().item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKbXKrZE0-Mo",
        "outputId": "ad3c6fe0-9794-4588-d15d-33126914217a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------\n",
            "bigram: .e\tindices: 0,5\n",
            "neural network input: 0\n",
            "output probabilities: tensor([0.0065, 0.0147, 0.0149, 0.0386, 0.0260, 0.0150, 0.0350, 0.0055, 0.0058,\n",
            "        0.0025, 0.0126, 0.0357, 0.0319, 0.0332, 0.0282, 0.1587, 0.0153, 0.0068,\n",
            "        0.0883, 0.0403, 0.2433, 0.0094, 0.0398, 0.0200, 0.0242, 0.0182, 0.0297])\n",
            "actual output [label]: 5\n",
            "predicted label probability: 0.015047615393996239\n",
            "log likelihood: -4.196535587310791\tnegative log likelihood: 4.196535587310791\n",
            "-------------------------\n",
            "-------------------------\n",
            "bigram: em\tindices: 5,13\n",
            "neural network input: 5\n",
            "output probabilities: tensor([0.0108, 0.0373, 0.0436, 0.0105, 0.0102, 0.0165, 0.0241, 0.0103, 0.1565,\n",
            "        0.0411, 0.0274, 0.0314, 0.0054, 0.0460, 0.0130, 0.0259, 0.0368, 0.0071,\n",
            "        0.0661, 0.0635, 0.0202, 0.0267, 0.0287, 0.0333, 0.1392, 0.0316, 0.0365])\n",
            "actual output [label]: 13\n",
            "predicted label probability: 0.046043794602155685\n",
            "log likelihood: -3.07816219329834\tnegative log likelihood: 3.07816219329834\n",
            "-------------------------\n",
            "-------------------------\n",
            "bigram: mm\tindices: 13,13\n",
            "neural network input: 13\n",
            "output probabilities: tensor([0.0106, 0.0257, 0.0100, 0.0362, 0.0035, 0.0116, 0.0426, 0.1217, 0.0122,\n",
            "        0.0041, 0.0221, 0.0513, 0.1904, 0.0458, 0.0067, 0.0326, 0.0191, 0.0270,\n",
            "        0.1061, 0.0093, 0.0112, 0.0307, 0.0313, 0.0737, 0.0388, 0.0023, 0.0232])\n",
            "actual output [label]: 13\n",
            "predicted label probability: 0.04584157094359398\n",
            "log likelihood: -3.082563877105713\tnegative log likelihood: 3.082563877105713\n",
            "-------------------------\n",
            "-------------------------\n",
            "bigram: ma\tindices: 13,1\n",
            "neural network input: 13\n",
            "output probabilities: tensor([0.0106, 0.0257, 0.0100, 0.0362, 0.0035, 0.0116, 0.0426, 0.1217, 0.0122,\n",
            "        0.0041, 0.0221, 0.0513, 0.1904, 0.0458, 0.0067, 0.0326, 0.0191, 0.0270,\n",
            "        0.1061, 0.0093, 0.0112, 0.0307, 0.0313, 0.0737, 0.0388, 0.0023, 0.0232])\n",
            "actual output [label]: 1\n",
            "predicted label probability: 0.025685619562864304\n",
            "log likelihood: -3.6618239879608154\tnegative log likelihood: 3.6618239879608154\n",
            "-------------------------\n",
            "-------------------------\n",
            "bigram: a.\tindices: 1,0\n",
            "neural network input: 1\n",
            "output probabilities: tensor([0.0654, 0.0347, 0.0089, 0.0934, 0.0672, 0.0109, 0.0355, 0.0105, 0.0110,\n",
            "        0.0121, 0.1224, 0.0514, 0.1211, 0.0025, 0.0340, 0.0173, 0.0170, 0.0432,\n",
            "        0.0262, 0.0153, 0.0034, 0.0448, 0.0240, 0.0157, 0.0156, 0.0446, 0.0518])\n",
            "actual output [label]: 0\n",
            "predicted label probability: 0.06542708724737167\n",
            "log likelihood: -2.7268190383911133\tnegative log likelihood: 2.7268190383911133\n",
            "-------------------------\n",
            "==============================\n",
            "average nll: 3.3491806983947754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We are interested in the probability that corresponds to the target : probs[input_idx , target_idx]\n",
        "# input_idx = [0 , 1 , 2 , 3 , 4]\n",
        "probs[torch.arange(5) , targets]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTMWPcr2V-Gi",
        "outputId": "0c19376e-1583-4365-813d-ccc5baba07ed"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0150, 0.0460, 0.0458, 0.0257, 0.0654])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This will help in finding the loss for the current iteration\n",
        "-probs[torch.arange(5) , targets].log().mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY3ucIBBWs0A",
        "outputId": "3afeb76e-7a16-4493-84f8-87722a9ef6f7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.3492)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 2147483647\n",
        "gen = torch.Generator().manual_seed(seed)\n",
        "W = torch.randn((27,27), generator = gen, requires_grad = True)"
      ],
      "metadata": {
        "id": "gOcaQpB8XiIz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass\n",
        "x_enc = F.one_hot(inputs, num_classes=len(tokens)).float()\n",
        "logits = x_enc @ W\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdims=True)\n",
        "\n",
        "# backward pass\n",
        "\n",
        "W.grad = None # This is equivalent to W.grad = 0\n",
        "loss = -probs[torch.arange(5), targets].log().mean()\n",
        "loss.backward()\n",
        "\n",
        "# optimization step\n",
        "W.data += -0.1 * W.grad"
      ],
      "metadata": {
        "id": "XHgUXBUkeO4o"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = x_enc @ W\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdims=True)\n",
        "loss = -probs[torch.arange(5), targets].log().mean()\n",
        "loss.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y07KHpoekRf",
        "outputId": "82d12658-4915-43a7-e0d1-ad02e163592e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.7492127418518066"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single Layer Neural Net"
      ],
      "metadata": {
        "id": "jMiOtxc4euCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('names.txt') as f:\n",
        "    names = f.read().splitlines()"
      ],
      "metadata": {
        "id": "VqZq7pdFewqw"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = ['.'] + list(string.ascii_lowercase) # Adding '.' in the list of tokens\n",
        "t_i = {t:i for i,t in enumerate(tokens)} # Converting characters to integers\n",
        "i_t = {i:t for t,i in t_i.items()} # Converting integers to characters"
      ],
      "metadata": {
        "id": "QV-qVb-eeybV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = []\n",
        "targets = []"
      ],
      "metadata": {
        "id": "ZZJ0jRs_ez8R"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in names:\n",
        "    word = ['.'] + list(word) + ['.']\n",
        "    for ch1, ch2 in zip(word,word[1:]):\n",
        "        r = t_i[ch1]\n",
        "        c = t_i[ch2]\n",
        "        # if the current bigram is ('.' , 'e') this means, for given input '.', the targetted output should be 'e'\n",
        "        inputs.append(r)\n",
        "        targets.append(c)"
      ],
      "metadata": {
        "id": "i9jHTRMWe1Lw"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor(inputs)\n",
        "targets = torch.tensor(targets)"
      ],
      "metadata": {
        "id": "OokZ9PmYfJTH"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nums = inputs.nelement()\n",
        "print(f\"Number of Bigram examples : {nums}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4Hzo3mVfLAz",
        "outputId": "b082d1ed-fbcc-406a-df87-83408088fb7d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Bigram examples : 228146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 2147483647\n",
        "generator = torch.Generator().manual_seed(seed)"
      ],
      "metadata": {
        "id": "NZoAiCCffSou"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = F.one_hot(inputs , num_classes = len(tokens)).float() # This will generate the one hot encoding for the given inputs. The size will be (inputs , 27)\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH10vFi5fu6v",
        "outputId": "f001f118-e778-4374-d31c-c972c86616ba"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([228146, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learningRate = 50 # Generally this will be between 0 to 0.001, but for this case, 50 also works\n",
        "epochs = 100"
      ],
      "metadata": {
        "id": "gvJePJIhgqg1"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.randn((27 , 27) , generator = generator , requires_grad = True)"
      ],
      "metadata": {
        "id": "GGnhI8KGg1X4"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nums = inputs.nelement()"
      ],
      "metadata": {
        "id": "gMMXBhA9hJAj"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1,epochs+1):\n",
        "  # forward pass:\n",
        "  logits = X @ W\n",
        "  counts = logits.exp()\n",
        "  probs = counts/counts.sum(1,keepdims=True)\n",
        "  loss = -probs[torch.arange(nums), targets].log().mean()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "      print(f\"loss at epoch {epoch}:\\t{loss.item()}\")\n",
        "\n",
        "  # backward pass:\n",
        "  W.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # optimization:\n",
        "  W.data += -learningRate * W.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP10Xn1Yg8e4",
        "outputId": "04c8e6f0-c9ca-4bfb-eec0-f622dfcd94b5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss at epoch 10:\t2.711496591567993\n",
            "loss at epoch 20:\t2.5794036388397217\n",
            "loss at epoch 30:\t2.5331544876098633\n",
            "loss at epoch 40:\t2.5103237628936768\n",
            "loss at epoch 50:\t2.4971446990966797\n",
            "loss at epoch 60:\t2.488725423812866\n",
            "loss at epoch 70:\t2.4829084873199463\n",
            "loss at epoch 80:\t2.4786536693573\n",
            "loss at epoch 90:\t2.4754140377044678\n",
            "loss at epoch 100:\t2.4728763103485107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The above W, its W.exp() is equivalent to the N table we obtained via counting.\n",
        "\n",
        "Note that we added fake counts to N (we added +1), the more we add, the more the probabilities are uniform and smooth in gradient-descent based learning,\n",
        "\n",
        "We can add regularization which is basically adding a large constant to the loss for more uniform loss\n",
        "\n",
        "Training loop with regularization:\n",
        "\"\"\"\n",
        "\n",
        "W = torch.randn((27,27),generator=gen, requires_grad=True)\n",
        "learningRate = 50\n",
        "epochs = 150\n",
        "\n",
        "for epoch in range(1,epochs+1):\n",
        "\n",
        "    # forward pass:\n",
        "    logits = X @ W\n",
        "    counts = logits.exp()\n",
        "    probs = counts/counts.sum(1,keepdims=True)\n",
        "\n",
        "    # regularization\n",
        "    regularization_const = torch.pow(W,2).mean()\n",
        "    lmb = 0.01 # more the lambda, more the const, more the impact on loss, more uniform the weights\n",
        "\n",
        "    # loss with regularization\n",
        "    loss = -probs[torch.arange(nums), targets].log().mean()\n",
        "    loss += lmb * regularization_const\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"loss at epoch {epoch}:\\t{loss.item()}\")\n",
        "\n",
        "    # backward pass:\n",
        "    W.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    # optimization:\n",
        "    W.data += -learningRate * W.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua-iQ-nBhVve",
        "outputId": "c3b3e3e4-24bd-4d45-dbbf-f82fbf1e6638"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss at epoch 10:\t2.707253932952881\n",
            "loss at epoch 20:\t2.586423635482788\n",
            "loss at epoch 30:\t2.544301986694336\n",
            "loss at epoch 40:\t2.5232653617858887\n",
            "loss at epoch 50:\t2.5112175941467285\n",
            "loss at epoch 60:\t2.50363826751709\n",
            "loss at epoch 70:\t2.4985363483428955\n",
            "loss at epoch 80:\t2.49491286277771\n",
            "loss at epoch 90:\t2.492231607437134\n",
            "loss at epoch 100:\t2.4901890754699707\n",
            "loss at epoch 110:\t2.4886012077331543\n",
            "loss at epoch 120:\t2.487346649169922\n",
            "loss at epoch 130:\t2.4863431453704834\n",
            "loss at epoch 140:\t2.485530376434326\n",
            "loss at epoch 150:\t2.4848647117614746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now sampling some examples\n",
        "seed = 2147483647\n",
        "gen = torch.Generator().manual_seed(seed)\n",
        "\n",
        "for i in range(25):\n",
        "  name = ''\n",
        "  idx = 0\n",
        "  while True:\n",
        "      x = F.one_hot(torch.tensor([idx]), num_classes=len(tokens)).float()\n",
        "      logits = x @ W\n",
        "      counts = logits.exp()\n",
        "      p = counts/counts.sum(1, keepdims=True)\n",
        "\n",
        "      idx = torch.multinomial(p,num_samples=1,replacement=True,generator=gen).item()\n",
        "      name += i_t[idx]\n",
        "      if idx == 0:\n",
        "          break\n",
        "  print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJxdJGlAjnyv",
        "outputId": "b1ded7a8-56de-4eba-92ef-d426836c865f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "junide.\n",
            "janasah.\n",
            "p.\n",
            "cfay.\n",
            "a.\n",
            "nn.\n",
            "kohin.\n",
            "tolian.\n",
            "juee.\n",
            "ksahnaauranilevias.\n",
            "dedainrwieta.\n",
            "ssonielylarte.\n",
            "faveumerifontume.\n",
            "phynslenaruani.\n",
            "core.\n",
            "yaenon.\n",
            "ka.\n",
            "jabdinerimikimaynin.\n",
            "anaasn.\n",
            "ssorionsush.\n",
            "dgossmitan.\n",
            "il.\n",
            "le.\n",
            "pann.\n",
            "that.\n"
          ]
        }
      ]
    }
  ]
}